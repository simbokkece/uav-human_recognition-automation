{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Take Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3964/902296138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtello\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTello\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtello\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtello\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreamon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\enforce_types.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mcheck_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self, wait_for_state)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \"\"\"Enter SDK mode. Call this before any of the control functions.\n\u001b[0;32m    533\u001b[0m         \"\"\"\n\u001b[1;32m--> 534\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_control_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"command\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwait_for_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\enforce_types.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mcheck_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\u001b[0m in \u001b[0;36msend_control_command\u001b[1;34m(self, command, timeout)\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"max retries exceeded\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command_with_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'ok'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\enforce_types.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mcheck_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\u001b[0m in \u001b[0;36msend_command_with_return\u001b[1;34m(self, command, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Sleep during send command\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_received_command_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from djitellopy import Tello\n",
    "\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "\n",
    "tello.streamon()\n",
    "print(drone.get_battery())\n",
    "# frame_read = tello.get_frame_read()\n",
    "\n",
    "# tello.takeoff()\n",
    "# cv2.imshow(\"picture.png\", frame_read.frame)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "# tello.land()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Recording Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'takeoff'\n",
      "[INFO] tello.py - 461 - Response takeoff: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'up 70'\n",
      "[INFO] tello.py - 461 - Response up 70: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'land'\n",
      "[INFO] tello.py - 461 - Response land: 'ok'\n"
     ]
    }
   ],
   "source": [
    "# # source https://github.com/damiafuentes/DJITelloPy\n",
    "# import time, cv2\n",
    "# from threading import Thread\n",
    "# from djitellopy import Tello\n",
    "\n",
    "# tello = Tello()\n",
    "\n",
    "# tello.connect()\n",
    "\n",
    "# keepRecording = True\n",
    "# tello.streamon()\n",
    "# frame_read = tello.get_frame_read()\n",
    "\n",
    "# def videoRecorder():\n",
    "#     # create a VideoWrite object, recoring to ./video.avi\n",
    "#     if (keepRecording == False):\n",
    "#         video.release()\n",
    "\n",
    "#     height, width, _ = frame_read.frame.shape\n",
    "#     video = cv2.VideoCapture(frame_read.frame)\n",
    "#     #vcv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'XVID'), 30, (width, height))\n",
    "\n",
    "#     while keepRecording:\n",
    "#         # video.write(frame_read.frame)\n",
    "#         ret, frame = video.read()\n",
    "#         time.sleep(1 / 30)\n",
    "\n",
    "\n",
    "# # we need to run the recorder in a seperate thread, otherwise blocking options\n",
    "# #  would prevent frames from getting added to the video\n",
    "# recorder = Thread(target=videoRecorder)\n",
    "# recorder.start()\n",
    "\n",
    "# keepRecording = False\n",
    "# videoRecorder()\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "# recorder.join()\n",
    "\n",
    "\n",
    "\n",
    "# source https://github.com/damiafuentes/DJITelloPy\n",
    "import time, cv2\n",
    "from threading import Thread\n",
    "from djitellopy import Tello\n",
    "\n",
    "tello = Tello()\n",
    "\n",
    "tello.connect()\n",
    "\n",
    "keepRecording = True\n",
    "tello.streamon()\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "def videoRecorder():\n",
    "    # create a VideoWrite object, recoring to ./video.avi\n",
    "   \n",
    "    height, width, _ = frame_read.frame.shape\n",
    "    video = cv2.VideoWriter('final_alter.avi', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, (width, height))\n",
    "\n",
    "    while keepRecording:\n",
    "        video.write(frame_read.frame)\n",
    "        time.sleep(1 / 30)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "# we need to run the recorder in a seperate thread, otherwise blocking options\n",
    "#  would prevent frames from getting added to the video\n",
    "recorder = Thread(target=videoRecorder)\n",
    "recorder.start()\n",
    "\n",
    "tello.takeoff()\n",
    "tello.move_up(70)\n",
    "# tello.rotate_counter_clockwise(360)\n",
    "tello.land()\n",
    "time.sleep(10)\n",
    "\n",
    "keepRecording = False\n",
    "recorder.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://github.com/damiafuentes/DJITelloPy\n",
    "import time, cv2\n",
    "from threading import Thread\n",
    "from djitellopy import Tello\n",
    "\n",
    "tello = Tello()\n",
    "\n",
    "tello.connect()\n",
    "\n",
    "keepRecording = True\n",
    "tello.streamon()\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "def videoRecorder():\n",
    "    # create a VideoWrite object, recoring to ./video.avi\n",
    "   \n",
    "    # height, width, _ = frame_read.frame.shape\n",
    "    # video = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'XVID'), 30, (width, height))\n",
    "\n",
    "    while keepRecording:\n",
    "        # video.write(frame_read.frame)\n",
    "        # ret, frame = frame_read.read()\n",
    "        print(frame_read.frame.shape)\n",
    "        # cv2.imshow('video', frame)\n",
    "        time.sleep(1 / 30)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "# we need to run the recorder in a seperate thread, otherwise blocking options\n",
    "#  would prevent frames from getting added to the video\n",
    "recorder = Thread(target=videoRecorder)\n",
    "recorder.start()\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    time.sleep(1)\n",
    "# tello.takeoff()\n",
    "# tello.move_up(100)\n",
    "# tello.rotate_counter_clockwise(360)\n",
    "# tello.land()\n",
    "\n",
    "keepRecording = False\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "recorder.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Applying Machine Learning (Face Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to grab first frame from video stream",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19244/2275707988.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\enforce_types.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mcheck_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\u001b[0m in \u001b[0;36mget_frame_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackground_frame_read\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0maddress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_udp_video_address\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackground_frame_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBackgroundFrameRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# also sets self.cap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackground_frame_read\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackground_frame_read\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tello, address)\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrabbed\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Failed to grab first frame from video stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Failed to grab first frame from video stream"
     ]
    }
   ],
   "source": [
    "from djitellopy import tello\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "drone = tello.Tello()\n",
    "drone.connect()\n",
    "print(drone.get_battery())\n",
    "\n",
    "drone.streamon()\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./cascades/haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./cascades/haarcascade_eye.xml')\n",
    "\n",
    "while True:\n",
    "    img = drone.get_frame_read().frame\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 3, minSize=(120, 120))\n",
    "        \n",
    "    for (x, y, w, h) in faces:\n",
    "        frame = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 5, minSize=(40, 40))\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(frame, (x+ex, y+ey), (x+ex+ew, y+ey+eh), (0, 255, 0), 2)\n",
    "    \n",
    "    # img = cv2.resize(img, (360, 360))\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    if cv2.waitKey(27) & 0xFF == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Applying Machine Learning (Object Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Detection with Frame from Tello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from djitellopy import tello\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "drone = tello.Tello()\n",
    "drone.connect()\n",
    "print(drone.get_battery())\n",
    "\n",
    "drone.streamon()\n",
    "\n",
    "def is_inside(i, o):\n",
    "    ix, iy, iw, ih = i\n",
    "    ox, oy, ow, oh = o\n",
    "    return ix > ox and ix + iw < ox + ow and \\\n",
    "    iy > oy and iy + ih < oy + oh\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "while True:\n",
    "    img = drone.get_frame_read().frame\n",
    "    found_rects, found_weights = hog.detectMultiScale(img, winStride=(4, 4), scale=1.05)\n",
    "\n",
    "    found_rects_filtered = []\n",
    "    found_weights_filtered = []\n",
    "\n",
    "    for ri, r in enumerate(found_rects):\n",
    "        for qi, q in enumerate(found_rects):\n",
    "            if ri != qi and is_inside(r, q):\n",
    "                break\n",
    "            else:\n",
    "                found_rects_filtered.append(r)\n",
    "                found_weights_filtered.append(found_weights[ri])\n",
    "    \n",
    "    for ri, r in enumerate(found_rects_filtered):\n",
    "        x, y, w, h = r\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        text = '%.2f' % found_weights_filtered[ri]\n",
    "        cv2.putText(img, text, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        if found_weights_filtered[ri] >= 4:\n",
    "            people_img = img\n",
    "    \n",
    "    # img = cv2.resize(img, (360, 360))\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    if cv2.waitKey(27) & 0xFF == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "418\n",
      "0.37799043062200954\n"
     ]
    }
   ],
   "source": [
    "count = 158\n",
    "frame_count = 418\n",
    "precision = count / frame_count\n",
    "\n",
    "print(count)\n",
    "print(frame_count)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Detection from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "210\n",
      "205.4393861935415\n"
     ]
    }
   ],
   "source": [
    "import cv2, time\n",
    "import os\n",
    "\n",
    "# output_folder = './detect_people'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "def is_inside(i, o):\n",
    "    ix, iy, iw, ih = i\n",
    "    ox, oy, ow, oh = o\n",
    "    return ix > ox and ix + iw < ox + ow and \\\n",
    "    iy > oy and iy + ih < oy + oh\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "vid = cv2.VideoCapture('footage-1.mp4')\n",
    "# vid = cv2.VideoCapture('hallway.mpg')\n",
    "frame_width = int(vid.get(3))\n",
    "frame_height = int(vid.get(4))\n",
    "\n",
    "out = cv2.VideoWriter('metopen-jauh.avi', cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width,frame_height))\n",
    "frame_count = 0\n",
    "total_fps = 0\n",
    "count = 0 \n",
    "\n",
    "while (cv2.waitKey(1) == -1):\n",
    "    success, frame = vid.read()\n",
    "    if success:\n",
    "        start_time = time.time()\n",
    "        found_rects, found_weights = hog.detectMultiScale(frame, winStride=(4, 4), padding=(4, 4), scale=1.03)\n",
    "        found_rects_filtered = []\n",
    "        found_weights_filtered = []\n",
    "\n",
    "        for ri, r in enumerate(found_rects):\n",
    "            for qi, q in enumerate(found_rects):\n",
    "                if ri != qi and is_inside(r, q):\n",
    "                    break\n",
    "                else:\n",
    "                    found_rects_filtered.append(r)\n",
    "                    found_weights_filtered.append(found_weights[ri])\n",
    "        \n",
    "        for ri, r in enumerate(found_rects_filtered):\n",
    "            x, y, w, h = r\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            text = '%.2f' % found_weights_filtered[ri]\n",
    "            cv2.putText(frame, text, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            if found_weights_filtered[ri] >= 1.1:\n",
    "                # people_img = frame\n",
    "                # filename = '%s/%d.png' % (output_folder, count)\n",
    "                # cv2.imwrite(filename, people_img)\n",
    "                # print(count)\n",
    "                count += 1\n",
    "\n",
    "        end_time = time.time()\n",
    "        fps = 1 / (end_time - start_time)\n",
    "        total_fps += fps\n",
    "        frame_count += 1\n",
    "\n",
    "        cv2.imshow('Detecting People', frame)\n",
    "        out.write(frame)\n",
    "\n",
    "        wait_time = max(1, int(fps/4))\n",
    "        if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "print(count)\n",
    "print(frame_count)\n",
    "print(total_fps)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "418\n",
      "449.89182205102094\n"
     ]
    }
   ],
   "source": [
    "import cv2, time\n",
    "import os\n",
    "\n",
    "# output_folder = './detect_people'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "def is_inside(i, o):\n",
    "    ix, iy, iw, ih = i\n",
    "    ox, oy, ow, oh = o\n",
    "    return ix > ox and ix + iw < ox + ow and \\\n",
    "    iy > oy and iy + ih < oy + oh\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "vid = cv2.VideoCapture('footage-2.mp4')\n",
    "# vid = cv2.VideoCapture('hallway.mpg')\n",
    "frame_width = int(vid.get(3))\n",
    "frame_height = int(vid.get(4))\n",
    "\n",
    "out = cv2.VideoWriter('metopen-termal.avi', cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width,frame_height))\n",
    "frame_count = 0\n",
    "total_fps = 0\n",
    "count = 0 \n",
    "\n",
    "while (cv2.waitKey(1) == -1):\n",
    "    success, frame = vid.read()\n",
    "    if success:\n",
    "        start_time = time.time()\n",
    "        found_rects, found_weights = hog.detectMultiScale(frame, winStride=(4, 4), padding=(4, 4), scale=1.03)\n",
    "        found_rects_filtered = []\n",
    "        found_weights_filtered = []\n",
    "\n",
    "        for ri, r in enumerate(found_rects):\n",
    "            for qi, q in enumerate(found_rects):\n",
    "                if ri != qi and is_inside(r, q):\n",
    "                    break\n",
    "                else:\n",
    "                    found_rects_filtered.append(r)\n",
    "                    found_weights_filtered.append(found_weights[ri])\n",
    "        \n",
    "        for ri, r in enumerate(found_rects_filtered):\n",
    "            x, y, w, h = r\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            text = '%.2f' % found_weights_filtered[ri]\n",
    "            cv2.putText(frame, text, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            if found_weights_filtered[ri] >= 0.5:\n",
    "                # people_img = frame\n",
    "                # filename = '%s/%d.png' % (output_folder, count)\n",
    "                # cv2.imwrite(filename, people_img)\n",
    "                # print(count)\n",
    "                count += 1\n",
    "\n",
    "        end_time = time.time()\n",
    "        fps = 1 / (end_time - start_time)\n",
    "        total_fps += fps\n",
    "        frame_count += 1\n",
    "\n",
    "        cv2.imshow('Detecting People', frame)\n",
    "        out.write(frame)\n",
    "\n",
    "        wait_time = max(1, int(fps/4))\n",
    "        if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "print(count)\n",
    "print(frame_count)\n",
    "print(total_fps)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4788/161399157.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read until end of video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# capture each frame of the video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# read until end of video\n",
    "while(cap.isOpened()):\n",
    "    # capture each frame of the video\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if args['speed'] == 'fast':\n",
    "            rects, weights = hog.detectMultiScale(img_gray, padding=(4, 4), scale=1.02)\n",
    "        elif args['speed'] == 'slow':\n",
    "            rects, weights = hog.detectMultiScale(img_gray, winStride=(4, 4), padding=(4, 4), scale=1.02)\n",
    "        for i, (x, y, w, h) in enumerate(rects):\n",
    "            if weights[i] < 0.13:\n",
    "                continue\n",
    "            elif weights[i] < 0.3 and weights[i] > 0.13:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            if weights[i] < 0.7 and weights[i] > 0.3:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (50, 122, 255), 2)\n",
    "            if weights[i] > 0.7:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'High confidence', (10, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Moderate confidence', (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 122, 255), 2)\n",
    "        cv2.putText(frame, 'Low confidence', (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        frame_write_name = args['input'].split('/')[-1].split('.')[0]\n",
    "        cv2.imwrite(f\"../outputs/frames/{args['speed']}_{frame_write_name}_{frame_count}.jpg\", frame)\n",
    "        \n",
    "        # Measure elapsed time for detections\n",
    "        end_time = time.time()\n",
    "        fps = 1 / (end_time - start_time)\n",
    "        # print(f\"{fps:.3f} FPS\")\n",
    "        # add to total FPS\n",
    "        total_fps += fps\n",
    "        # add to total number of frames\n",
    "        frame_count += 1\n",
    "        cv2.imshow(\"Preview\", frame)\n",
    "        out.write(frame)\n",
    "        # press `q` to exit\n",
    "        wait_time = max(1, int(fps/4))\n",
    "        if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MQTT Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MQTT Broker!\n",
      "1.00\n",
      "4.83\n",
      "4.85\n",
      "1.00\n",
      "4.83\n",
      "1.00\n",
      "4.83\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from paho.mqtt import client as mqtt_client\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "broker = '192.168.10.10'\n",
    "port = 1883\n",
    "# topic = \"/esp/light\"\n",
    "client_id = f'python-mqtt-{random.randint(0, 100)}'\n",
    "light = 0\n",
    "ultrasonic = 0\n",
    "\n",
    "def connect_mqtt() -> mqtt_client:\n",
    "    def on_connect(client, userdata, flags, rc):\n",
    "        if rc == 0:\n",
    "            print(\"Connected to MQTT Broker!\")\n",
    "        else:\n",
    "            print(\"Failed to connect, return code %d\\n\", rc)\n",
    "\n",
    "    client = mqtt_client.Client(client_id)\n",
    "    client.on_connect = on_connect\n",
    "    client.connect(broker, port)\n",
    "    return client\n",
    "\n",
    "def subscribe(client: mqtt_client):\n",
    "    def on_message(client, userdata, msg):\n",
    "        global light\n",
    "        global ultrasonic\n",
    "        \n",
    "        if msg.topic == \"/esp/light\":\n",
    "        #     print(\"Batterie Sally \\t\\t ==> \\t \" + str(msg.payload + \"%\"))\n",
    "            # print(f\"Received `{msg.payload.decode()}` from `{msg.topic}` topic\")\n",
    "            light = msg.payload.decode('UTF-8')\n",
    "            print(light)\n",
    "        if msg.topic == \"/esp/ultrasonic\":\n",
    "            if msg.payload == \"1.00\":\n",
    "                ultrasonic = msg.payload.decode('UTF-8')\n",
    "                print(ultrasonic)\n",
    "            else:\n",
    "                # print(f\"Received `{msg.payload.decode()}` from `{msg.topic}` topic\")\n",
    "                ultrasonic = msg.payload.decode('UTF-8')\n",
    "                print(ultrasonic)\n",
    "        # light = msg.payload.decode('UTF-8')\n",
    "        # print(f\"Received `{msg.payload.decode()}` from `{msg.topic}` topic\")\n",
    "\n",
    "    client.subscribe('/esp/ultrasonic')\n",
    "    client.subscribe('/esp/light')\n",
    "    client.on_message = on_message\n",
    "\n",
    "def run():\n",
    "    client = connect_mqtt()\n",
    "    subscribe(client)\n",
    "    for i in range(0, 10):\n",
    "        client.loop_start()\n",
    "        time.sleep(1)\n",
    "    client.loop_stop()\n",
    "    # client.disconnect()\n",
    "\n",
    "run()\n",
    "print(light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import paho.mqtt.client as paho\n",
    "\n",
    "broker = '192.168.10.10'\n",
    "broker = \"iot.eclipse.org\"\n",
    "\n",
    "def on_message(client, userdata, message):\n",
    "    time.sleep(1)\n",
    "    print(\"received message =\",str(message.payload.decode(\"utf-8\")))\n",
    "\n",
    "client= paho.Client(\"client-001\") #create client object \n",
    "client1.on_publish = on_publish #assign function to callback \n",
    "client1.connect(broker,port) #establish connection \n",
    "client1.publish(\"house/bulb1\",\"on\")\n",
    "\n",
    "client.on_message=on_message\n",
    "\n",
    "print(\"connecting to broker \",broker)\n",
    "client.connect(broker)#connect\n",
    "client.loop_start() #start loop to process received messages\n",
    "print(\"subscribing \")\n",
    "client.subscribe(\"house/bulb1\")#subscribe\n",
    "time.sleep(2)\n",
    "print(\"publishing \")\n",
    "client.publish(\"house/bulb1\",\"on\")#publish\n",
    "time.sleep(4)\n",
    "client.disconnect() #disconnect\n",
    "client.loop_stop() #stop loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Database Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Succesfully Connected!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "conn = mysql.connector.connect(host='localhost',\n",
    "                               user='iee2020',\n",
    "                               password='iee2020',\n",
    "                               database=\"smartdrone\")\n",
    "\n",
    "print(\"Database Succesfully Connected!\")\n",
    "c = conn.cursor(buffered=True)\n",
    "\n",
    "def update_data(obyek, people, light):\n",
    "    c.execute(f'''insert into environment(object_count, human_count, light_condition)\n",
    "                values(\"{obyek}\", \"{people}\", \"{light}\");''')\n",
    "    conn.commit()\n",
    "\n",
    "object1 = 100\n",
    "people1 = 10\n",
    "light = 10\n",
    "\n",
    "# update_data(object1, people1, light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "Connected to MQTT Broker!\n",
      "0\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 437 - Send command: 'takeoff'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00\n",
      "1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 461 - Response takeoff: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'up 70'\n",
      "[INFO] tello.py - 461 - Response up 70: 'ok'\n",
      "[INFO] tello.py - 437 - Send command: 'land'\n",
      "[INFO] tello.py - 461 - Response land: 'ok'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\", line 1065, in update_frame\n",
      "    self.stop()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\", line 1074, in stop\n",
      "    self.worker.join()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 1050, in join\n",
      "    raise RuntimeError(\"cannot join current thread\")\n",
      "RuntimeError: cannot join current thread\n"
     ]
    }
   ],
   "source": [
    "import random, time, cv2\n",
    "from paho.mqtt import client as mqtt_client\n",
    "from threading import Thread\n",
    "from djitellopy import Tello\n",
    "\n",
    "keepRecording = True\n",
    "is_thread = False\n",
    "\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "# tello.connect_to_wifi(ssid=\"IEELab_002\", password=\"\")\n",
    "tello.streamon()\n",
    "frame_read = tello.get_frame_read()\n",
    "print(tello.get_battery())\n",
    "\n",
    "# broker = '10.252.240.74'\n",
    "broker = '192.168.10.10'\n",
    "port = 1883\n",
    "topic1 = \"/esp/ultrasonic\"\n",
    "topic2 = \"/esp/light\"\n",
    "client_id = f'python-mqtt-{random.randint(0, 100)}'\n",
    "ultrasonic = 0\n",
    "light = 0\n",
    "\n",
    "def videoRecorder():\n",
    "    global is_thread\n",
    "\n",
    "    height, width, _ = frame_read.frame.shape\n",
    "    video = cv2.VideoWriter('final.avi', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, (width, height))\n",
    "\n",
    "    while keepRecording:\n",
    "        video.write(frame_read.frame)\n",
    "        time.sleep(1 / 30)\n",
    "\n",
    "    is_thread = True\n",
    "    video.release()\n",
    "\n",
    "def connect_mqtt() -> mqtt_client:\n",
    "    def on_connect(client, userdata, flags, rc):\n",
    "        if rc == 0:\n",
    "            print(\"Connected to MQTT Broker!\")\n",
    "        else:\n",
    "            print(\"Failed to connect, return code %d\\n\", rc)\n",
    "\n",
    "    client = mqtt_client.Client(client_id)\n",
    "    client.on_connect = on_connect\n",
    "    client.connect(broker, port)\n",
    "    return client\n",
    "\n",
    "def subscribe(client: mqtt_client):\n",
    "    def on_message(client, userdata, msg):\n",
    "        global light\n",
    "        global ultrasonic\n",
    "        global is_thread\n",
    "        \n",
    "        if msg.topic == \"/esp/light\":\n",
    "            light = msg.payload.decode('UTF-8')\n",
    "            # print(light)\n",
    "        if msg.topic == \"/esp/ultrasonic\":\n",
    "            if msg.payload == \"1.00\":\n",
    "                ultrasonic = msg.payload.decode('UTF-8')\n",
    "                # print(ultrasonic)\n",
    "            else:\n",
    "                ultrasonic = msg.payload.decode('UTF-8')\n",
    "                # print(ultrasonic)\n",
    "\n",
    "    client.subscribe(topic1)\n",
    "    client.subscribe(topic2)\n",
    "    client.on_message = on_message\n",
    "\n",
    "def run():\n",
    "    global is_thread\n",
    "\n",
    "    is_thread = False\n",
    "    client = connect_mqtt()\n",
    "    subscribe(client)\n",
    "    for i in range(0, 20):\n",
    "        client.loop_start()\n",
    "        print(ultrasonic)\n",
    "        if (ultrasonic == '1.00'):\n",
    "            if (is_thread == False):\n",
    "                print(ultrasonic)\n",
    "                is_thread = True\n",
    "                break\n",
    "            else:\n",
    "                print(is_thread)\n",
    "                pass\n",
    "            # print(payloads)\n",
    "            time.sleep(1)\n",
    "                \n",
    "        # print(payloads)\n",
    "        time.sleep(1)\n",
    "    client.loop_stop()\n",
    "\n",
    "recorder = Thread(target=videoRecorder)\n",
    "run()\n",
    "\n",
    "recorder.start()\n",
    "tello.takeoff()\n",
    "tello.move_up(70)\n",
    "time.sleep(5)\n",
    "# tello.move_up(30)\n",
    "tello.land()\n",
    "\n",
    "is_thread = False\n",
    "keepRecording = False\n",
    "recorder.join()\n",
    "# tello.land()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\", line 1065, in update_frame\n",
      "    self.stop()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\djitellopy\\tello.py\", line 1074, in stop\n",
      "    self.worker.join()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 1050, in join\n",
      "    raise RuntimeError(\"cannot join current thread\")\n",
      "RuntimeError: cannot join current thread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "Average FPS: 2.271\n"
     ]
    }
   ],
   "source": [
    "import cv2, time\n",
    "import os\n",
    "\n",
    "output_folder = './detect_people'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "def is_inside(i, o):\n",
    "    ix, iy, iw, ih = i\n",
    "    ox, oy, ow, oh = o\n",
    "    return ix > ox and ix + iw < ox + ow and \\\n",
    "    iy > oy and iy + ih < oy + oh\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "vid = cv2.VideoCapture('final_alter.avi')\n",
    "frame_width = int(vid.get(3))\n",
    "frame_height = int(vid.get(4))\n",
    "\n",
    "out = cv2.VideoWriter('object_detection2.avi', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, (frame_width,frame_height))\n",
    "frame_count = 0\n",
    "total_fps = 0\n",
    "count = 0 \n",
    "\n",
    "while (cv2.waitKey(1) == -1):\n",
    "    success, frame = vid.read()\n",
    "    if success:\n",
    "        start_time = time.time()\n",
    "        found_rects, found_weights = hog.detectMultiScale(frame, winStride=(4, 4), padding=(4, 4), scale=1.05)\n",
    "        found_rects_filtered = []\n",
    "        found_weights_filtered = []\n",
    "\n",
    "        for ri, r in enumerate(found_rects):\n",
    "            for qi, q in enumerate(found_rects):\n",
    "                if ri != qi and is_inside(r, q):\n",
    "                    break\n",
    "                else:\n",
    "                    found_rects_filtered.append(r)\n",
    "                    found_weights_filtered.append(found_weights[ri])\n",
    "        \n",
    "        for ri, r in enumerate(found_rects_filtered):\n",
    "            x, y, w, h = r\n",
    "            if found_weights_filtered[ri] >= 3:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                text = '%.2f' % found_weights_filtered[ri]\n",
    "                cv2.putText(frame, text, (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                \n",
    "                people_img = frame\n",
    "                filename = '%s/%d.png' % (output_folder, count)\n",
    "                cv2.imwrite(filename, people_img)\n",
    "                # print(count)\n",
    "                count += 1\n",
    "\n",
    "        end_time = time.time()\n",
    "        fps = 1 / (end_time - start_time)\n",
    "        total_fps += fps\n",
    "        frame_count += 1\n",
    "\n",
    "        cv2.imshow('Detecting People', frame)\n",
    "        out.write(frame)\n",
    "\n",
    "        wait_time = max(1, int(fps/4))\n",
    "        if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "avg_fps = total_fps / frame_count\n",
    "print(count)\n",
    "print(f\"Average FPS: {avg_fps:.3f}\" )\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultrasonic = 1.00\n",
    "light = 4.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Succesfully Connected!\n",
      "\n",
      "  no   date_added            object_count    human_count    light  \n",
      "\n",
      "  1    2022-12-02 01:27:45        1               6         4.96   \n",
      "\n",
      "  2    2022-12-02 14:00:02        1              483        4.69   \n",
      "\n",
      "  3    2022-12-08 17:52:33        1              59         4.76   \n",
      "\n",
      "Records created successfully\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from tabulate import tabulate\n",
    "\n",
    "conn = mysql.connector.connect(host='localhost',\n",
    "                               user='iee2020',\n",
    "                               password='iee2020',\n",
    "                               database=\"smartdrone\")\n",
    "\n",
    "print(\"Database Succesfully Connected!\")\n",
    "c = conn.cursor(buffered=True)\n",
    "\n",
    "def update_data(obyek, people, light):\n",
    "    c.execute(f'''insert into environment(object_count, human_count, light_condition)\n",
    "                values(\"{obyek}\", \"{people}\", \"{light}\");''')\n",
    "    conn.commit()\n",
    "\n",
    "# ultrasonic = 1\n",
    "# light = 4.96\n",
    "update_data(ultrasonic, count, light)\n",
    "\n",
    "c.execute('''select * from environment''')\n",
    "table = [['no', 'date_added', 'object_count', 'human_count', 'light']]\n",
    "x = c.fetchall()\n",
    "\n",
    "for row in x:\n",
    "    data = [row[0], row[1], row[2], row[3], row[4]]\n",
    "    table.append(data)\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid', numalign='center'))\n",
    "conn.commit()\n",
    "print(\"Records created successfully\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
